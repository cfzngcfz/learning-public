{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ed620a",
   "metadata": {},
   "source": [
    "分类 | APA | Cited by | paper & note\n",
    ":- | :- | -: | :-\n",
    "Transformer | Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). **Attention is all you need**. Advances in neural information processing systems, 30. | 97197 | [paper](Attention_is_all_you_need.pdf) [note](Attention_Is_All_You_Need.ipynb)\n",
    "|\n",
    "Gaia-1 |Hu, A., Russell, L., Yeo, H., Murez, Z., Fedoseev, G., Kendall, A., ... & Corrado, G. (2023). **Gaia-1: A generative world model for autonomous driving**. arXiv preprint arXiv:2309.17080. | 5 | [paper](Gaia1_A_generative_world_model_for_autonomous_driving.pdf)\n",
    "|\n",
    "MotionLM | Seff, A., Cera, B., Chen, D., Ng, M., Zhou, A., Nayakanti, N., ... & Sapp, B. (2023). **Motionlm: Multi-agent motion forecasting as language modeling**. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 8579-8590). | 2 | [paper](MotionLM_Multi_Agent_Motion_Forecasting_as_Language_Modeling.pdf) [note](MotionLM_Multi_Agent_Motion_Forecasting_as_Language_Modeling.ipynb)\n",
    "|\n",
    "JFP | Luo, W., Park, C., Cornman, A., Sapp, B., & Anguelov, D. (2023, March). **JFP: Joint future prediction with interactive multi-agent modeling for autonomous driving**. In Conference on Robot Learning (pp. 1457-1467). PMLR. | 13 | [paper](JFP_Joint_future_prediction_with_interactive_multi_agent_modeling_for_autonomous_driving.pdf)\n",
    "|\n",
    "Wayformer | Nayakanti, N., Al-Rfou, R., Zhou, A., Goel, K., Refaat, K. S., & Sapp, B. (2023, May). **Wayformer: Motion forecasting via simple & efficient attention networks**. In 2023 IEEE International Conference on Robotics and Automation (ICRA) (pp. 2980-2987). IEEE. | 86 | [paper](Wayformer_Motion_Forecasting_via_Simple_and_Efficient_Attention_Networks.pdf)\n",
    "|\n",
    "Multipath++ | Varadarajan, B., Hefny, A., Srivastava, A., Refaat, K. S., Nayakanti, N., Cornman, A., ... & Sapp, B. (2022, May). **Multipath++: Efficient information fusion and trajectory aggregation for behavior prediction**. In 2022 International Conference on Robotics and Automation (ICRA) (pp. 7814-7821). IEEE. | 133 | [paper](Multipath_Efficient_information_fusion_and_trajectory_aggregation_for_behavior_prediction.pdf)\n",
    "|\n",
    "RT1 | Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Dabis, J., Finn, C., ... & Zitkovich, B. (2022). **Rt-1: Robotics transformer for real-world control at scale**. arXiv preprint arXiv:2212.06817. | 210 | [paper](Rt1_Robotics_transformer_for_real_world_control_at_scale.pdf)\n",
    "|\n",
    "RT-2 | Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Chen, X., Choromanski, K., ... & Zitkovich, B. (2023). **Rt-2: Vision-language-action models transfer web knowledge to robotic control**. arXiv preprint arXiv:2307.15818. | 81 | [paper](Rt2_Vision_language_action_models_transfer_web_knowledge_to_robotic_control)\n",
    "|\n",
    "NeRF | Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi, R., & Ng, R. (2021). **Nerf: Representing scenes as neural radiance fields for view synthesis**. Communications of the ACM, 65(1), 99-106. | 4549 | [paper](Nerf_Representing_scenes_as_neural_radiance_fields_for_view_synthesis) [github](https://github.com/bmild/nerf)\n",
    "| [知乎: 都2022年了，我不允许你还不懂NeRF](https://zhuanlan.zhihu.com/p/569843149?utm_campaign=shareopn&utm_medium=social&utm_oi=1130406216324726784&utm_psn=1700685621876695040&utm_source=wechat_session&utm_id=0)\n",
    "| [bilibili: NeRF数学公式从零推导，物理背景很重要](https://www.bilibili.com/video/BV1Wd4y1X7H1/?spm_id_from=333.880.my_history.page.click&vd_source=30ad97c43aadccd54ea9aabd72b47f3e)\n",
    "| https://github.com/sjtuytc/UnboundedNeRFPytorch/blob/main/docs/nerf_tutorials/nerf_math_Chinese.pdf\n",
    "|\n",
    "NeRF | Tancik, M., Casser, V., Yan, X., Pradhan, S., Mildenhall, B., Srinivasan, P. P., ... & Kretzschmar, H. (2022). **Block-nerf: Scalable large scene neural view synthesis**. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 8248-8258). | 291 | [paper](Block_NeRF_Scalable_Large_Scene_Neural_View_Synthesis.pdf)\n",
    "|\n",
    "NeRF | Deng, C., Jiang, C., Qi, C. R., Yan, X., Zhou, Y., Guibas, L., & Anguelov, D. (2023). **Nerdi: Single-view nerf synthesis with language-guided diffusion as general image priors**. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 20637-20647). | 27 | [paper](NeRDi_Single_View_NeRF_Synthesis_with_Language-Guided_Diffusion_As_General_Image_Priors.pdf)\n",
    "|\n",
    "Reinforcement Learning | Lu, Y., Fu, J., Tucker, G., Pan, X., Bronstein, E., Roelofs, B., ... & Levine, S. (2022). **Imitation is not enough: Robustifying imitation with reinforcement learning for challenging driving scenarios**. arXiv preprint arXiv:2212.11419. | 20 | [paper](Imitation_is_not_enough_Robustifying_imitation_with_reinforcement_learning_for_challenging_driving_scenarios.pdf)\n",
    "|\n",
    "| Assaad, S., Downey, C., Al-Rfou, R., Nayakanti, N., & Sapp, B. (2022). **Vn-transformer: Rotation-equivariant attention for vector neurons**. arXiv preprint arXiv:2206.04176. | 6 | [paper](VN_Transformer_Rotation_Equivariant_Attention_for_Vector_Neurons.pdf)\n",
    "|\n",
    "| Su, D. A., Douillard, B., Al-Rfou, R., Park, C., & Sapp, B. (2022, May). **Narrowing the coordinate-frame gap in behavior prediction models: Distillation for efficient and accurate scene-centric motion forecasting**. In 2022 International Conference on Robotics and Automation (ICRA) (pp. 653-659). IEEE. | 5 | [paper](Narrowing_the_coordinate_frame_gap_in_behavior_prediction_models_Distillation_for_efficient_and_accurate_scene_centric_motion_forecasting.pdf)\n",
    "| \n",
    "| Roelofs, R., Sun, L., Caine, B., Refaat, K. S., Sapp, B., Ettinger, S., & Chai, W. (2022). **Causalagents: A robustness benchmark for motion forecasting using causal relationships**. arXiv preprint arXiv:2207.03586. | 1 | [paper](Causalagents_A_robustness_benchmark_for_motion_forecasting_using_causal_relationships.pdf)\n",
    "|\n",
    "state space | Singh, A., Makhlouf, O., Igl, M., Messias, J., Doucet, A., & Whiteson, S. (2023, March). **Particle-Based Score Estimation for State Space Model Learning in Autonomous Driving**. In Conference on Robot Learning (pp. 1168-1177). PMLR. | 0 | [paper](Particle_Based_Score_Estimation_for_State_Space_Model_Learning_in_Autonomous_Driving.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00dbab",
   "metadata": {},
   "source": [
    "https://waymo.com/research/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
