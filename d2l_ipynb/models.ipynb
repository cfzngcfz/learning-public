{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9bb68cbe",
   "metadata": {},
   "source": [
    "# 线性回归的简洁实现\n",
    "[3.3节](./03.linear-networks.ipynb#线性回归的简洁实现)\n",
    "![image.png](attachment:image.png)\n",
    "$$\\hat{y} = w_1  x_1 + ... + w_d  x_d + b = \\mathbf{w}^\\top \\mathbf{x} + b,\\ where\\ \\mathbf{x} \\in \\mathbb{R}^d, \\mathbf{w} \\in \\mathbb{R}^d$$\n",
    "$${\\hat{\\mathbf{y}}} = \\mathbf{X} \\mathbf{w} + b,\\ where\\ \\mathbf{X} \\in \\mathbb{R}^{n \\times d}$$\n",
    "$\\mathbf{X}$的每一行是一个样本.\n",
    "Sequential类将多个层串联在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 生成数据集\n",
    "def synthetic_data(w, b, num_examples):\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "\n",
    "print(features.size())\n",
    "print(labels.size())\n",
    "# plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1)\n",
    "\n",
    "# 读取数据集\n",
    "batch_size = 10\n",
    "data_iter = data.DataLoader(data.TensorDataset(features, labels), batch_size=batch_size, shuffle=True)\n",
    "X, y = next(iter(data_iter))\n",
    "print(\"X =\\n\", X)\n",
    "print(\"y =\\n\", y)\n",
    "\n",
    "# 定义模型\n",
    "net = nn.Sequential(nn.Linear(2, 1))\n",
    "print(net)\n",
    "\n",
    "# 参数初始化\n",
    "\"\"\"\n",
    "1. 通过`net[0]`选择网络中的第一个图层\n",
    "2. 使用`weight.data`和`bias.data`方法访问参数\n",
    "3. 使用替换方法`normal_`和`fill_`来重写参数值\n",
    "\"\"\"\n",
    "print(net[0].weight.data)\n",
    "print(net[0].bias.data)\n",
    "print(net[0].weight.data.normal_(0, 0.01))\n",
    "print(net[0].bias.data.fill_(1))\n",
    "\n",
    "# 验证模型和初始化参数\n",
    "y_hat = torch.matmul(X, net[0].weight.data.T) + net[0].bias.data\n",
    "print(torch.equal(y_hat, net(X)))\n",
    "\n",
    "# 损失函数\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# 验证损失函数值\n",
    "torch.sum((y_hat - y) ** 2)/y.numel()\n",
    "loss(net(X) ,y)\n",
    "\n",
    "# 优化算法\n",
    "\"\"\"待优化的参数可通过net.parameters()获得\"\"\"\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "\n",
    "# 训练\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()         # 将模型设置为训练模式\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X) ,y) # 计算损失函数loss（前向传播）\n",
    "        trainer.zero_grad()\n",
    "        l.backward()        # 进行反向传播来计算梯度\n",
    "        trainer.step()      # 用优化器来更新模型参数\n",
    "    \n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()          # 将模型设置为评估模式\n",
    "    with torch.no_grad():\n",
    "        l = loss(net(features), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {l:f}')\n",
    "\n",
    "w = net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b0af2",
   "metadata": {},
   "source": [
    "# softmax回归的简洁实现\n",
    "[3.7节](./03.linear-networks.ipynb#softmax回归的简洁实现)  \n",
    "$n$样本数量, $d$单个样本的输入维度, $q$单个样本的输出维度, 即种类总数  \n",
    "单个样本的loss:\n",
    "$$\\begin{split}\\begin{aligned}\n",
    "l(\\mathbf{y}, \\hat{\\mathbf{y}}) &= - \\sum_{j=1}^q y_j \\log \\hat{y}_j \\ (\\because \\hat{y}_j = \\mathrm{softmax}(o_j) = \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)})\\\\\n",
    "&=  - \\sum_{j=1}^q y_j \\log \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} \\\\\n",
    "&= \\sum_{j=1}^q y_j \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j \\ (\\because \\sum_{j=1}^q y_j = 1)\\\\\n",
    "&= \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j\n",
    "\\end{aligned}\\end{split}$$\n",
    "其导数:\n",
    "$$ \\frac{\\partial  l(\\mathbf{y}, \\hat{\\mathbf{y}})}{\\partial {o_j}} = \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} - y_j = \\mathrm{softmax}(o_j) - y_j $$\n",
    "\n",
    "$n$个样本的loss:\n",
    "$$ \\sum_{i=1}^n l(\\mathbf{y}^{(i)}, \\hat{\\mathbf{y}}^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision, time\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# 下载数据集\n",
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root=\"../../temp\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST( root=\"../../temp\", train=False, transform=trans, download=True)\n",
    "print(\"训练集中的样本数量 =\", len(mnist_train), \", 测试集中的样本数量\", len(mnist_test))\n",
    "print(\"size of input of first sample =\", mnist_train[0][0].shape)\n",
    "print(\"label of first sample =\", mnist_train[0][1])\n",
    "\n",
    "# 读取数据集\n",
    "## 部分数据可视化\n",
    "def get_fashion_mnist_labels(labels):\n",
    "    \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"绘制图像列表\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # 图片张量\n",
    "            ax.imshow(img.numpy())\n",
    "        else:\n",
    "            # PIL图片\n",
    "            ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes\n",
    "batch_size = 10\n",
    "data_iter = data.DataLoader(mnist_train,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,  # 随机打乱所有样本\n",
    "                            num_workers=4) # 使用4个进程来读取数据                                                              \n",
    "\n",
    "X, y = next(iter(data_iter))\n",
    "show_images(X.reshape(batch_size, 28, 28), 2, int(batch_size/2), titles=get_fashion_mnist_labels(y))\n",
    "\n",
    "## 多进程来读取数据对比\n",
    "start = time.time()\n",
    "for X, y in data.DataLoader(mnist_train, batch_size=256):\n",
    "    continue\n",
    "end = time.time()\n",
    "print(end - start, \"sec\")\n",
    "\n",
    "start = time.time()\n",
    "for X, y in data.DataLoader(mnist_train, batch_size=256, num_workers=4):\n",
    "    continue\n",
    "end = time.time()\n",
    "print(end - start, \"sec\")\n",
    "\n",
    "## 训练和测试数据\n",
    "batch_size = 256\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4)\n",
    "test_iter = data.DataLoader(mnist_test, batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# 定义模型\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "print(net)\n",
    "\n",
    "# 参数初始化\n",
    "for ii in range(len(net)):\n",
    "    print(ii, type(net[ii]) == nn.Linear)\n",
    "net[1].weight.data.normal_(0.0, 0.01) # 方法1\n",
    "# nn.init.normal_(net[1].weight, mean=0.0, std=0.01) # 方法2\n",
    "print(net[1].weight.data)\n",
    "\n",
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# 验证\n",
    "## 验证 softmax 函数\n",
    "X2 = torch.normal(0, 1, (2, 5))\n",
    "print(\"X2 =\\n\", X2)\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition\n",
    "X_prob = softmax(X2)\n",
    "print(\"X_prob =\\n\", X_prob)\n",
    "### 分步验证\n",
    "X_exp = torch.exp(X2)\n",
    "print(\"X_exp =\\n\", X_exp)\n",
    "partition = X_exp.sum(1, keepdim=True)\n",
    "print(\"partition =\\n\", partition)\n",
    "X_prob = X_exp / partition\n",
    "print(\"X_prob =\\n\", X_prob)\n",
    "print(\"sum of X_prob = \", X_prob.sum(1))\n",
    "\n",
    "## 验证模型和初始参数\n",
    "X, y = next(iter(data_iter))\n",
    "Output = torch.matmul(X.reshape((-1, net[1].weight.data.T.shape[0])), net[1].weight.data.T) + net[1].bias.data\n",
    "print(torch.equal(Output, net(X)))\n",
    "\n",
    "## 验证loss\n",
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n",
    "y_hat = softmax(Output)\n",
    "print(\"y =\", y)\n",
    "print(cross_entropy(y_hat, y))\n",
    "print(loss(net(X) ,y))\n",
    "\n",
    "# 优化算法\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "# 训练\n",
    "## 准备(累加器和动画)\n",
    "class Accumulator: # 累加器\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "class Animator:\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: self.set_axes(self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "        \n",
    "    def set_axes(self, axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"Set the axes for matplotlib\"\"\"\n",
    "        axes.set_xlabel(xlabel)\n",
    "        axes.set_ylabel(ylabel)\n",
    "        axes.set_xscale(xscale)\n",
    "        axes.set_yscale(yscale)\n",
    "        axes.set_xlim(xlim)\n",
    "        axes.set_ylim(ylim)\n",
    "        if legend:\n",
    "            axes.legend(legend)\n",
    "        axes.grid()\n",
    "        \n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "## 定义分类正确函数\n",
    "\"\"\"分类概率->分类结果\"\"\"\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"计算分类正确次数\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "### 分步验证\n",
    "if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "print(\"y_hat =\", y_hat) \n",
    "print(\"y =    \", y) # y_hat & y defined in 验证loss\n",
    "cmp = y_hat.type(y.dtype) == y # 由于等式运算符“==”对数据类型很敏感， 因此我们将y_hat的数据类型转换为与y的数据类型一致\n",
    "print(\"cmp =  \", cmp)\n",
    "print(\"分类正确的次数 =\", float(cmp.type(y.dtype).sum()))\n",
    "\n",
    "## 使用训练集，训练模型\n",
    "def train(net, train_iter, loss, optimizer):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()                    # 将模型设置为训练模式\n",
    "    metric = Accumulator(3)            # 累加器\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)             # 计算损失函数loss（前向传播）\n",
    "        optimizer.zero_grad()\n",
    "        l.mean().backward()            # 进行反向传播来计算梯度\n",
    "        optimizer.step()               # 用优化器来更新模型参数\n",
    "\n",
    "        metric.add(float(l.sum()),     # 训练损失总和\n",
    "                   accuracy(y_hat, y), # 训练准确度总和\n",
    "                   y.size(0))          # 样本数\n",
    "    return metric[0] / metric[2], metric[1] / metric[2] # 返回训练集的平均损失和分类准确率\n",
    "\n",
    "## 使用测试集，评估模型\n",
    "def evaluate(net, test_iter):\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()                          # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)                 # 累加器\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_iter:\n",
    "            metric.add(accuracy(net(X), y), # 当前分类正确次数\n",
    "                       y.size(0))           # 当前样本数量\n",
    "\n",
    "    return metric[0] / metric[1]           # 返回测试集的分类准确率\n",
    "\n",
    "## 运行多个迭代周期。 在每个迭代周期结束时，利用test_iter访问到的测试数据集对模型进行评估\n",
    "num_epochs = 10\n",
    "animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=[\"train loss\", \"train acc\", \"test acc\"])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_metrics = train(net, train_iter, loss, optimizer) # 训练模型\n",
    "    test_acc = evaluate(net, test_iter)                     # 评估模型\n",
    "    print(epoch + 1, \"train loss =\", train_metrics[0], \", train acc =\", train_metrics[1], \", test acc =\", test_acc)\n",
    "    animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "\n",
    "train_loss, train_acc = train_metrics\n",
    "assert train_loss < 0.5, train_loss\n",
    "assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "\n",
    "# 预测\n",
    "num_samples = 8\n",
    "X, y = next(iter(data.DataLoader(mnist_test, num_samples, shuffle=True)))\n",
    "labels = get_fashion_mnist_labels(y)\n",
    "outputs = get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "titles = [true +'\\n' + pred for true, pred in zip(labels, outputs)]\n",
    "show_images(torch.squeeze(X), 1, num_samples, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8a2e5",
   "metadata": {},
   "source": [
    "# 带参数注意力汇聚\n",
    "[10.2.4节](./10.attention-mechanisms.ipynb#带参数注意力汇聚)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a94b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------- x_train, keys, values ----------------------\n",
    "\n",
    "n_train = 50  # 训练样本数\n",
    "x_train, _ = torch.sort(torch.rand(n_train) * 5) # 排序后的训练样本\n",
    "def f(x):\n",
    "    return 2 * torch.sin(x) + x**0.8\n",
    "y_train = f(x_train) + torch.normal(0.0, 0.5, (n_train,)) # 训练样本的输出\n",
    "\n",
    "# X_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输入\n",
    "X_tile = x_train.repeat((n_train, 1))\n",
    "# Y_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输出\n",
    "Y_tile = y_train.repeat((n_train, 1))\n",
    "\n",
    "# keys的形状:('n_train'，'n_train'-1)\n",
    "keys = X_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))\n",
    "# values的形状:('n_train'，'n_train'-1)\n",
    "values = Y_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))\n",
    "\n",
    "# ---------------------- training ----------------------\n",
    "\n",
    "class NWKernelRegression(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = nn.Parameter(torch.rand((1,), requires_grad=True))\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # queries和attention_weights的形状为(查询个数，“键－值”对个数)\n",
    "        queries = torch.reshape(x_train.repeat_interleave(keys.shape[1]), (-1, keys.shape[1]))\n",
    "        self.attention_weights = nn.functional.softmax(-((queries - keys) * self.w)**2 / 2, dim=1)\n",
    "        # values的形状为(查询个数，“键－值”对个数)\n",
    "        return torch.bmm(self.attention_weights.unsqueeze(1), values.unsqueeze(-1)).reshape(-1)\n",
    "\n",
    "net = NWKernelRegression()\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "\n",
    "for epoch in range(5):\n",
    "    trainer.zero_grad()\n",
    "    l = loss(net(x_train, keys, values), y_train)\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    print(f'epoch {epoch + 1}, loss {float(l.sum()):.6f}')\n",
    "\n",
    "# ---------------------- verification ----------------------\n",
    "\n",
    "def plot_kernel_reg(y_hat):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x_test, y_truth, label='Truth')\n",
    "    ax.plot(x_test, y_hat, label='Pred', linestyle='--')\n",
    "    ax.plot(x_train, y_train, 'o', alpha=0.5);\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlim([0, 5])\n",
    "    ax.set_ylim([-1, 5])\n",
    "    ax.grid(True)\n",
    "    \n",
    "x_test = torch.arange(0, 5, 0.1)  # 测试样本\n",
    "y_truth = f(x_test)  # 测试样本的真实输出\n",
    "n_test = len(x_test)  # 测试样本数\n",
    "# keys的形状:(n_test，n_train)，每一行包含着相同的训练输入（例如，相同的键）\n",
    "keys = x_train.repeat((n_test, 1))\n",
    "# value的形状:(n_test，n_train)\n",
    "values = y_train.repeat((n_test, 1))\n",
    "\n",
    "y_hat = net(x_test, keys, values).unsqueeze(1).detach()\n",
    "plot_kernel_reg(y_hat)\n",
    "\n",
    "# ---------------------- attention weights ----------------------\n",
    "\n",
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(16, 9),\n",
    "                  cmap='Reds'):\n",
    "    \"\"\"显示矩阵热图\"\"\"\n",
    "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, sharex=True, sharey=True, squeeze=False)\n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "    fig.colorbar(pcm, ax=axes, shrink=0.6);\n",
    "\n",
    "show_heatmaps(net.attention_weights.unsqueeze(0).unsqueeze(0),\n",
    "              xlabel='Sorted training inputs',\n",
    "              ylabel='Sorted testing inputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7105fa",
   "metadata": {},
   "source": [
    "# Bahdanau 注意力\n",
    "[10.4节](./10.attention-mechanisms.ipynb#Bahdanau-注意力)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch, os, zipfile, tarfile, hashlib, requests, collections, math\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "\n",
    "def try_gpu(i=0):\n",
    "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\n",
    "\n",
    "    Defined in :numref:`sec_use_gpu`\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 250, try_gpu()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n",
    "DATA_HUB['fra-eng'] = (DATA_URL + 'fra-eng.zip', '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "def download(name, cache_dir=os.path.join('..', 'data')):\n",
    "    \"\"\"Download a file inserted into DATA_HUB, return the local filename.\n",
    "\n",
    "    Defined in :numref:`sec_kaggle_house`\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} does not exist in {DATA_HUB}.\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # Hit cache\n",
    "    print(f'Downloading {fname} from {url}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname\n",
    "\n",
    "def download_extract(name, folder=None):\n",
    "    \"\"\"Download and extract a zip/tar file.\n",
    "\n",
    "    Defined in :numref:`sec_kaggle_house`\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, 'Only zip/tar files can be extracted.'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def read_data_nmt():\n",
    "    \"\"\"Load the English-French dataset.\n",
    "\n",
    "    Defined in :numref:`sec_machine_translation`\"\"\"\n",
    "    data_dir = download_extract('fra-eng')\n",
    "    with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding=\"UTF-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def preprocess_nmt(text):\n",
    "    \"\"\"Preprocess the English-French dataset.\n",
    "\n",
    "    Defined in :numref:`sec_machine_translation`\"\"\"\n",
    "    def no_space(char, prev_char):\n",
    "        return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "    # Replace non-breaking space with space, and convert uppercase letters to\n",
    "    # lowercase ones\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    # Insert space between words and punctuation marks\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "           for i, char in enumerate(text)]\n",
    "    return ''.join(out)\n",
    "\n",
    "def tokenize_nmt(text, num_examples=None):\n",
    "    \"\"\"Tokenize the English-French dataset.\n",
    "\n",
    "    Defined in :numref:`sec_machine_translation`\"\"\"\n",
    "    source, target = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples:\n",
    "            break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            source.append(parts[0].split(' '))\n",
    "            target.append(parts[1].split(' '))\n",
    "    return source, target\n",
    "\n",
    "def count_corpus(tokens):\n",
    "    \"\"\"Count token frequencies.\n",
    "\n",
    "    Defined in :numref:`sec_text_preprocessing`\"\"\"\n",
    "    # Here `tokens` is a 1D list or 2D list\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # Flatten a list of token lists into a list of tokens\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"Vocabulary for text.\"\"\"\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
    "        \"\"\"Defined in :numref:`sec_text_preprocessing`\"\"\"\n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        # Sort according to frequencies\n",
    "        counter = count_corpus(tokens)\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                   reverse=True)\n",
    "        # The index for the unknown token is 0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):  # Index for the unknown token\n",
    "        return self._token_freqs\n",
    "\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    \"\"\"Truncate or pad sequences.\n",
    "\n",
    "    Defined in :numref:`sec_machine_translation`\"\"\"\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "\n",
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "    \"\"\"Transform text sequences of machine translation into minibatches.\n",
    "\n",
    "    Defined in :numref:`subsec_mt_data_loading`\"\"\"\n",
    "    reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\n",
    "    astype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\n",
    "\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = torch.tensor([truncate_pad(\n",
    "        l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = reduce_sum(\n",
    "        astype(array != vocab['<pad>'], torch.int32), 1)\n",
    "    return array, valid_len\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator.\n",
    "\n",
    "    Defined in :numref:`sec_linear_concise`\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "    \"\"\"Return the iterator and the vocabularies of the translation dataset.\n",
    "\n",
    "    Defined in :numref:`subsec_mt_data_loading`\"\"\"\n",
    "    text = preprocess_nmt(read_data_nmt())\n",
    "    source, target = tokenize_nmt(text, num_examples)\n",
    "    src_vocab = Vocab(source, min_freq=2,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    tgt_vocab = Vocab(target, min_freq=2,\n",
    "                          reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "    data_iter = load_array(data_arrays, batch_size)\n",
    "    return data_iter, src_vocab, tgt_vocab\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"The base encoder interface for the encoder-decoder architecture.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Seq2SeqEncoder(Encoder):\n",
    "    \"\"\"The RNN encoder for sequence to sequence learning.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq`\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                  dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "\n",
    "    def forward(self, X, *args):\n",
    "        # The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)\n",
    "        X = self.embedding(X)\n",
    "        # In RNN models, the first axis corresponds to time steps\n",
    "        X = X.permute(1, 0, 2)\n",
    "        # When state is not mentioned, it defaults to zeros\n",
    "        output, state = self.rnn(X)\n",
    "        # `output` shape: (`num_steps`, `batch_size`, `num_hiddens`)\n",
    "        # `state` shape: (`num_layers`, `batch_size`, `num_hiddens`)\n",
    "        return output, state\n",
    "\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"The base decoder interface for the encoder-decoder architecture.\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class AttentionDecoder(Decoder):\n",
    "    \"\"\"带有注意力机制解码器的基本接口\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionDecoder, self).__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"Mask irrelevant entries in sequences.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32, device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "\n",
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\"\"\"\n",
    "    # X:3D张量，valid_lens:1D或2D张量\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=0)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
    "\n",
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"Additive attention.\n",
    "\n",
    "    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        # After dimension expansion, shape of `queries`: (`batch_size`, no. of\n",
    "        # queries, 1, `num_hiddens`) and shape of `keys`: (`batch_size`, 1,\n",
    "        # no. of key-value pairs, `num_hiddens`). Sum them up with\n",
    "        # broadcasting\n",
    "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
    "        features = torch.tanh(features)\n",
    "        # There is only one output of `self.w_v`, so we remove the last\n",
    "        # one-dimensional entry from the shape. Shape of `scores`:\n",
    "        # (`batch_size`, no. of queries, no. of key-value pairs)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        # Shape of `values`: (`batch_size`, no. of key-value pairs, value\n",
    "        # dimension)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "\n",
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
    "        self.attention = AdditiveAttention(\n",
    "            num_hiddens, num_hiddens, num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(\n",
    "            embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "            dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        # outputs的形状为(batch_size，num_steps，num_hiddens).\n",
    "        # hidden_state的形状为(num_layers，batch_size，num_hiddens)\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # enc_outputs的形状为(batch_size,num_steps,num_hiddens).\n",
    "        # hidden_state的形状为(num_layers,batch_size,\n",
    "        # num_hiddens)\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        # 输出X的形状为(num_steps,batch_size,embed_size)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        outputs, self._attention_weights = [], []\n",
    "        for x in X:\n",
    "            # query的形状为(batch_size,1,num_hiddens)\n",
    "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            # context的形状为(batch_size,1,num_hiddens)\n",
    "            context = self.attention(\n",
    "                query, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "            # 在特征维度上连结\n",
    "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
    "            # 将x变形为(1,batch_size,embed_size+num_hiddens)\n",
    "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
    "            outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        # 全连接层变换后，outputs的形状为\n",
    "        # (num_steps,batch_size,vocab_size)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n",
    "                                          enc_valid_lens]\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights\n",
    "\n",
    "decoder = Seq2SeqAttentionDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"The base class for the encoder-decoder architecture.\n",
    "\n",
    "    Defined in :numref:`sec_encoder-decoder`\"\"\"\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "        return self.decoder(dec_X, dec_state)\n",
    "\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "        \n",
    "import time\n",
    "import numpy as np\n",
    "class Timer:\n",
    "    \"\"\"Record multiple running times.\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Defined in :numref:`subsec_linear_model`\"\"\"\n",
    "        self.times = []\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.tik = time.time()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and record the time in a list.\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "\n",
    "    def avg(self):\n",
    "        \"\"\"Return the average time.\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of time.\"\"\"\n",
    "        return sum(self.times)\n",
    "\n",
    "    def cumsum(self):\n",
    "        \"\"\"Return the accumulated time.\"\"\"\n",
    "        return np.array(self.times).cumsum().tolist()\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def grad_clipping(net, theta):\n",
    "    \"\"\"Clip the gradient.\n",
    "\n",
    "    Defined in :numref:`sec_rnn_scratch`\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm\n",
    "\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"Train a model for sequence to sequence.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = Timer()\n",
    "        metric = Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                                device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n",
    "          f'tokens/sec on {str(device)}')\n",
    "\n",
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_training`\"\"\"\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # Add the batch axis\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # We use the token with the highest prediction likelihood as the input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n",
    "\n",
    "def bleu(pred_seq, label_seq, k):\n",
    "    \"\"\"Compute the BLEU.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_training`\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score\n",
    "\n",
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{eng} => {translation}, ',\n",
    "          f'bleu {bleu(translation, fra, k=2):.3f}')\n",
    "\n",
    "attention_weights = torch.cat([step[0][0][0] for step in dec_attention_weight_seq], 0).reshape((\n",
    "    1, 1, -1, num_steps))\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(4, 3), cmap='Reds'):\n",
    "    \"\"\"显示矩阵热图\"\"\"\n",
    "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, sharex=True, sharey=True, squeeze=False)\n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "    fig.colorbar(pcm, ax=axes, shrink=0.6)\n",
    "\n",
    "# 加上一个包含序列结束词元\n",
    "show_heatmaps(\n",
    "    attention_weights[:, :, :, :len(engs[-1].split()) + 1].cpu(),\n",
    "    xlabel='Key positions', ylabel='Query positions')dd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
