{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9bb68cbe",
   "metadata": {},
   "source": [
    "# 线性回归的简洁实现\n",
    "[3.3节](./03.linear-networks.ipynb#线性回归的简洁实现)\n",
    "![image.png](attachment:image.png)\n",
    "$$\\hat{y} = w_1  x_1 + ... + w_d  x_d + b = \\mathbf{w}^\\top \\mathbf{x} + b,\\ where\\ \\mathbf{x} \\in \\mathbb{R}^d, \\mathbf{w} \\in \\mathbb{R}^d$$\n",
    "$${\\hat{\\mathbf{y}}} = \\mathbf{X} \\mathbf{w} + b,\\ where\\ \\mathbf{X} \\in \\mathbb{R}^{n \\times d}$$\n",
    "$\\mathbf{X}$的每一行是一个样本.\n",
    "Sequential类将多个层串联在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 生成数据集\n",
    "def synthetic_data(w, b, num_examples):\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "\n",
    "print(features.size())\n",
    "print(labels.size())\n",
    "# plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1)\n",
    "\n",
    "# 读取数据集\n",
    "batch_size = 10\n",
    "data_iter = data.DataLoader(data.TensorDataset(features, labels), batch_size=batch_size, shuffle=True)\n",
    "X, y = next(iter(data_iter))\n",
    "print(\"X =\\n\", X)\n",
    "print(\"y =\\n\", y)\n",
    "\n",
    "# 定义模型\n",
    "net = nn.Sequential(nn.Linear(2, 1))\n",
    "print(net)\n",
    "\n",
    "# 参数初始化\n",
    "\"\"\"\n",
    "1. 通过`net[0]`选择网络中的第一个图层\n",
    "2. 使用`weight.data`和`bias.data`方法访问参数\n",
    "3. 使用替换方法`normal_`和`fill_`来重写参数值\n",
    "\"\"\"\n",
    "print(net[0].weight.data)\n",
    "print(net[0].bias.data)\n",
    "print(net[0].weight.data.normal_(0, 0.01))\n",
    "print(net[0].bias.data.fill_(1))\n",
    "\n",
    "# 验证模型和初始化参数\n",
    "y_hat = torch.matmul(X, net[0].weight.data.T) + net[0].bias.data\n",
    "print(torch.equal(y_hat, net(X)))\n",
    "\n",
    "# 损失函数\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# 验证损失函数值\n",
    "torch.sum((y_hat - y) ** 2)/y.numel()\n",
    "loss(net(X) ,y)\n",
    "\n",
    "# 优化算法\n",
    "\"\"\"待优化的参数可通过net.parameters()获得\"\"\"\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "\n",
    "# 训练\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()         # 将模型设置为训练模式\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X) ,y) # 计算损失函数loss（前向传播）\n",
    "        trainer.zero_grad()\n",
    "        l.backward()        # 进行反向传播来计算梯度\n",
    "        trainer.step()      # 用优化器来更新模型参数\n",
    "    \n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()          # 将模型设置为评估模式\n",
    "    with torch.no_grad():\n",
    "        l = loss(net(features), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {l:f}')\n",
    "\n",
    "w = net[0].weight.data\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b0af2",
   "metadata": {},
   "source": [
    "# softmax回归的简洁实现\n",
    "[3.7节](./03.linear-networks.ipynb#softmax回归的简洁实现)  \n",
    "$n$样本数量, $d$单个样本的输入维度, $q$单个样本的输出维度, 即种类总数  \n",
    "单个样本的loss:\n",
    "$$\\begin{split}\\begin{aligned}\n",
    "l(\\mathbf{y}, \\hat{\\mathbf{y}}) &= - \\sum_{j=1}^q y_j \\log \\hat{y}_j \\ (\\because \\hat{y}_j = \\mathrm{softmax}(o_j) = \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)})\\\\\n",
    "&=  - \\sum_{j=1}^q y_j \\log \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} \\\\\n",
    "&= \\sum_{j=1}^q y_j \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j \\ (\\because \\sum_{j=1}^q y_j = 1)\\\\\n",
    "&= \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j\n",
    "\\end{aligned}\\end{split}$$\n",
    "其导数:\n",
    "$$ \\frac{\\partial  l(\\mathbf{y}, \\hat{\\mathbf{y}})}{\\partial {o_j}} = \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} - y_j = \\mathrm{softmax}(o_j) - y_j $$\n",
    "\n",
    "$n$个样本的loss:\n",
    "$$ \\sum_{i=1}^n l(\\mathbf{y}^{(i)}, \\hat{\\mathbf{y}}^{(i)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision, time\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# 下载数据集\n",
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root=\"../../temp\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST( root=\"../../temp\", train=False, transform=trans, download=True)\n",
    "print(\"训练集中的样本数量 =\", len(mnist_train), \", 测试集中的样本数量\", len(mnist_test))\n",
    "print(\"size of input of first sample =\", mnist_train[0][0].shape)\n",
    "print(\"label of first sample =\", mnist_train[0][1])\n",
    "\n",
    "# 读取数据集\n",
    "## 部分数据可视化\n",
    "def get_fashion_mnist_labels(labels):\n",
    "    \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n",
    "    \"\"\"绘制图像列表\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # 图片张量\n",
    "            ax.imshow(img.numpy())\n",
    "        else:\n",
    "            # PIL图片\n",
    "            ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes\n",
    "batch_size = 10\n",
    "data_iter = data.DataLoader(mnist_train,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,  # 随机打乱所有样本\n",
    "                            num_workers=4) # 使用4个进程来读取数据                                                              \n",
    "\n",
    "X, y = next(iter(data_iter))\n",
    "show_images(X.reshape(batch_size, 28, 28), 2, int(batch_size/2), titles=get_fashion_mnist_labels(y))\n",
    "\n",
    "## 多进程来读取数据对比\n",
    "start = time.time()\n",
    "for X, y in data.DataLoader(mnist_train, batch_size=256):\n",
    "    continue\n",
    "end = time.time()\n",
    "print(end - start, \"sec\")\n",
    "\n",
    "start = time.time()\n",
    "for X, y in data.DataLoader(mnist_train, batch_size=256, num_workers=4):\n",
    "    continue\n",
    "end = time.time()\n",
    "print(end - start, \"sec\")\n",
    "\n",
    "## 训练和测试数据\n",
    "batch_size = 256\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4)\n",
    "test_iter = data.DataLoader(mnist_test, batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# 定义模型\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "print(net)\n",
    "\n",
    "# 参数初始化\n",
    "for ii in range(len(net)):\n",
    "    print(ii, type(net[ii]) == nn.Linear)\n",
    "net[1].weight.data.normal_(0.0, 0.01) # 方法1\n",
    "# nn.init.normal_(net[1].weight, mean=0.0, std=0.01) # 方法2\n",
    "print(net[1].weight.data)\n",
    "\n",
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# 验证\n",
    "## 验证 softmax 函数\n",
    "X2 = torch.normal(0, 1, (2, 5))\n",
    "print(\"X2 =\\n\", X2)\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition\n",
    "X_prob = softmax(X2)\n",
    "print(\"X_prob =\\n\", X_prob)\n",
    "### 分步验证\n",
    "X_exp = torch.exp(X2)\n",
    "print(\"X_exp =\\n\", X_exp)\n",
    "partition = X_exp.sum(1, keepdim=True)\n",
    "print(\"partition =\\n\", partition)\n",
    "X_prob = X_exp / partition\n",
    "print(\"X_prob =\\n\", X_prob)\n",
    "print(\"sum of X_prob = \", X_prob.sum(1))\n",
    "\n",
    "## 验证模型和初始参数\n",
    "X, y = next(iter(data_iter))\n",
    "Output = torch.matmul(X.reshape((-1, net[1].weight.data.T.shape[0])), net[1].weight.data.T) + net[1].bias.data\n",
    "print(torch.equal(Output, net(X)))\n",
    "\n",
    "## 验证loss\n",
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n",
    "y_hat = softmax(Output)\n",
    "print(\"y =\", y)\n",
    "print(cross_entropy(y_hat, y))\n",
    "print(loss(net(X) ,y))\n",
    "\n",
    "# 优化算法\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "\n",
    "# 训练\n",
    "## 准备(累加器和动画)\n",
    "class Accumulator: # 累加器\n",
    "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "class Animator:\n",
    "    \"\"\"在动画中绘制数据\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # 增量地绘制多条线\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # 使用lambda函数捕获参数\n",
    "        self.config_axes = lambda: self.set_axes(self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "        \n",
    "    def set_axes(self, axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "        \"\"\"Set the axes for matplotlib\"\"\"\n",
    "        axes.set_xlabel(xlabel)\n",
    "        axes.set_ylabel(ylabel)\n",
    "        axes.set_xscale(xscale)\n",
    "        axes.set_yscale(yscale)\n",
    "        axes.set_xlim(xlim)\n",
    "        axes.set_ylim(ylim)\n",
    "        if legend:\n",
    "            axes.legend(legend)\n",
    "        axes.grid()\n",
    "        \n",
    "    def add(self, x, y):\n",
    "        # 向图表中添加多个数据点\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "## 定义分类正确函数\n",
    "\"\"\"分类概率->分类结果\"\"\"\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"计算分类正确次数\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "### 分步验证\n",
    "if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "    y_hat = y_hat.argmax(axis=1)\n",
    "print(\"y_hat =\", y_hat) \n",
    "print(\"y =    \", y) # y_hat & y defined in 验证loss\n",
    "cmp = y_hat.type(y.dtype) == y # 由于等式运算符“==”对数据类型很敏感， 因此我们将y_hat的数据类型转换为与y的数据类型一致\n",
    "print(\"cmp =  \", cmp)\n",
    "print(\"分类正确的次数 =\", float(cmp.type(y.dtype).sum()))\n",
    "\n",
    "## 使用训练集，训练模型\n",
    "def train(net, train_iter, loss, optimizer):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()                    # 将模型设置为训练模式\n",
    "    metric = Accumulator(3)            # 累加器\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)             # 计算损失函数loss（前向传播）\n",
    "        optimizer.zero_grad()\n",
    "        l.mean().backward()            # 进行反向传播来计算梯度\n",
    "        optimizer.step()               # 用优化器来更新模型参数\n",
    "\n",
    "        metric.add(float(l.sum()),     # 训练损失总和\n",
    "                   accuracy(y_hat, y), # 训练准确度总和\n",
    "                   y.size(0))          # 样本数\n",
    "    return metric[0] / metric[2], metric[1] / metric[2] # 返回训练集的平均损失和分类准确率\n",
    "\n",
    "## 使用测试集，评估模型\n",
    "def evaluate(net, test_iter):\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()                          # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)                 # 累加器\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_iter:\n",
    "            metric.add(accuracy(net(X), y), # 当前分类正确次数\n",
    "                       y.size(0))           # 当前样本数量\n",
    "\n",
    "    return metric[0] / metric[1]           # 返回测试集的分类准确率\n",
    "\n",
    "## 运行多个迭代周期。 在每个迭代周期结束时，利用test_iter访问到的测试数据集对模型进行评估\n",
    "num_epochs = 10\n",
    "animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=[\"train loss\", \"train acc\", \"test acc\"])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_metrics = train(net, train_iter, loss, optimizer) # 训练模型\n",
    "    test_acc = evaluate(net, test_iter)                     # 评估模型\n",
    "    print(epoch + 1, \"train loss =\", train_metrics[0], \", train acc =\", train_metrics[1], \", test acc =\", test_acc)\n",
    "    animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "\n",
    "train_loss, train_acc = train_metrics\n",
    "assert train_loss < 0.5, train_loss\n",
    "assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "\n",
    "# 预测\n",
    "num_samples = 8\n",
    "X, y = next(iter(data.DataLoader(mnist_test, num_samples, shuffle=True)))\n",
    "labels = get_fashion_mnist_labels(y)\n",
    "outputs = get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "titles = [true +'\\n' + pred for true, pred in zip(labels, outputs)]\n",
    "show_images(torch.squeeze(X), 1, num_samples, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8a2e5",
   "metadata": {},
   "source": [
    "# 带参数注意力汇聚\n",
    "[10.2.4节](./10.attention-mechanisms.ipynb#带参数注意力汇聚)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a94b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------- x_train, keys, values ----------------------\n",
    "\n",
    "n_train = 50  # 训练样本数\n",
    "x_train, _ = torch.sort(torch.rand(n_train) * 5) # 排序后的训练样本\n",
    "def f(x):\n",
    "    return 2 * torch.sin(x) + x**0.8\n",
    "y_train = f(x_train) + torch.normal(0.0, 0.5, (n_train,)) # 训练样本的输出\n",
    "\n",
    "# X_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输入\n",
    "X_tile = x_train.repeat((n_train, 1))\n",
    "# Y_tile的形状:(n_train，n_train)，每一行都包含着相同的训练输出\n",
    "Y_tile = y_train.repeat((n_train, 1))\n",
    "\n",
    "# keys的形状:('n_train'，'n_train'-1)\n",
    "keys = X_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))\n",
    "# values的形状:('n_train'，'n_train'-1)\n",
    "values = Y_tile[(1 - torch.eye(n_train)).type(torch.bool)].reshape((n_train, -1))\n",
    "\n",
    "# ---------------------- training ----------------------\n",
    "\n",
    "class NWKernelRegression(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.w = nn.Parameter(torch.rand((1,), requires_grad=True))\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # queries和attention_weights的形状为(查询个数，“键－值”对个数)\n",
    "        queries = torch.reshape(x_train.repeat_interleave(keys.shape[1]), (-1, keys.shape[1]))\n",
    "        self.attention_weights = nn.functional.softmax(-((queries - keys) * self.w)**2 / 2, dim=1)\n",
    "        # values的形状为(查询个数，“键－值”对个数)\n",
    "        return torch.bmm(self.attention_weights.unsqueeze(1), values.unsqueeze(-1)).reshape(-1)\n",
    "\n",
    "net = NWKernelRegression()\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "\n",
    "for epoch in range(5):\n",
    "    trainer.zero_grad()\n",
    "    l = loss(net(x_train, keys, values), y_train)\n",
    "    l.sum().backward()\n",
    "    trainer.step()\n",
    "    print(f'epoch {epoch + 1}, loss {float(l.sum()):.6f}')\n",
    "\n",
    "# ---------------------- verification ----------------------\n",
    "\n",
    "def plot_kernel_reg(y_hat):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(x_test, y_truth, label='Truth')\n",
    "    ax.plot(x_test, y_hat, label='Pred', linestyle='--')\n",
    "    ax.plot(x_train, y_train, 'o', alpha=0.5);\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlim([0, 5])\n",
    "    ax.set_ylim([-1, 5])\n",
    "    ax.grid(True)\n",
    "    \n",
    "x_test = torch.arange(0, 5, 0.1)  # 测试样本\n",
    "y_truth = f(x_test)  # 测试样本的真实输出\n",
    "n_test = len(x_test)  # 测试样本数\n",
    "# keys的形状:(n_test，n_train)，每一行包含着相同的训练输入（例如，相同的键）\n",
    "keys = x_train.repeat((n_test, 1))\n",
    "# value的形状:(n_test，n_train)\n",
    "values = y_train.repeat((n_test, 1))\n",
    "\n",
    "y_hat = net(x_test, keys, values).unsqueeze(1).detach()\n",
    "plot_kernel_reg(y_hat)\n",
    "\n",
    "# ---------------------- attention weights ----------------------\n",
    "\n",
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(16, 9),\n",
    "                  cmap='Reds'):\n",
    "    \"\"\"显示矩阵热图\"\"\"\n",
    "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, sharex=True, sharey=True, squeeze=False)\n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "    fig.colorbar(pcm, ax=axes, shrink=0.6);\n",
    "\n",
    "show_heatmaps(net.attention_weights.unsqueeze(0).unsqueeze(0),\n",
    "              xlabel='Sorted training inputs',\n",
    "              ylabel='Sorted testing inputs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
